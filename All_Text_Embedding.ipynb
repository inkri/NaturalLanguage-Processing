{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479c069-dd31-480a-8dcf-71c5937c7223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef9d9609-e4be-4c84-bd2e-4d025a3cc495",
   "metadata": {},
   "source": [
    "# One-Hot Encoding (OHE):\n",
    "## Categorical data consists of discrete and unordered categories or labels. Examples include color names, city names, or any other non-numeric labels.ries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de421e1-3310-4e82-a655-a2a7cc8b0e3f",
   "metadata": {},
   "source": [
    "## Methodology: Represents each categorical variable as a binary vector where only one element is 1, indicating the category.\n",
    "## When to Use: Simple representation for categorical variables when there's no inherent ordinal relationship.\n",
    "## Advantage: Easy to implement and understand.\n",
    "## Disadvantage: High-dimensional, doesn't capture relationships between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a44531-aaf5-4b18-98a8-e167ac9e0165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Category\n",
      "0      Red\n",
      "1    Green\n",
      "2     Blue\n",
      "3      Red\n",
      "4    Green\n",
      "\n",
      "One-Hot Encoded DataFrame:\n",
      "  Category  Category_Blue  Category_Green  Category_Red\n",
      "0      Red            0.0             0.0           1.0\n",
      "1    Green            0.0             1.0           0.0\n",
      "2     Blue            1.0             0.0           0.0\n",
      "3      Red            0.0             0.0           1.0\n",
      "4    Green            0.0             1.0           0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Sample categorical data\n",
    "data = {'Category': ['Red', 'Green', 'Blue', 'Red', 'Green']}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "one_hot_encoded = encoder.fit_transform(df[['Category']]).toarray()\n",
    "\n",
    "# Create a new DataFrame with one-hot encoded values\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(['Category']))\n",
    "\n",
    "# Concatenate the original DataFrame and the one-hot encoded DataFrame\n",
    "result_df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nOne-Hot Encoded DataFrame:\")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0344da3-4684-4011-8db8-d76f12e05dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98ef4ec-eea0-42aa-9c64-9b9b2ebee85b",
   "metadata": {},
   "source": [
    "# Ordinal Categorical Embedding\n",
    "## Ordinal data involves categories with a specific order or ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d9f3f-ca73-44a3-876e-9ed8c12ca557",
   "metadata": {},
   "source": [
    "## Methodology: Assigns a unique numerical value to each category based on its ordinal position.\n",
    "## When to Use: When there is a clear ordinal relationship between categories.\n",
    "## Advantage: Captures ordinal information.\n",
    "## Disadvantage: Assumes equal spacing between categories, may not represent true relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3acb422b-19d9-46c1-a0c9-2c9075fd1902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Satisfaction  Satisfaction_Encoded\n",
      "0       Medium                   1.0\n",
      "1          Low                   0.0\n",
      "2         High                   2.0\n",
      "3       Medium                   1.0\n",
      "4          Low                   0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Sample ordinal data\n",
    "data = {'Satisfaction': ['Medium', 'Low', 'High', 'Medium', 'Low']}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Use OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
    "ordinal_encoded = encoder.fit_transform(df[['Satisfaction']])\n",
    "\n",
    "# Add the encoded column to the original DataFrame\n",
    "df['Satisfaction_Encoded'] = ordinal_encoded\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4f75d-e3b4-47da-b9c5-cf801d7f08d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c8965a-cff2-4e70-bb8a-d2c4fda25d79",
   "metadata": {},
   "source": [
    "# Bag-of-Words (BoW):\n",
    "## Overview: BoW represents a document as an unordered set of words, disregarding grammar and word order. Each word is assigned a unique index, and the vector is created by counting the occurrences of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6a5833-edc9-4b49-987e-e4959086e6a6",
   "metadata": {},
   "source": [
    "## Methodology: Represents a document as an unordered set of words, ignoring grammar and word order.\n",
    "## When to Use: Text classification, sentiment analysis, and document retrieval.\n",
    "## Advantage: Simple, computationally efficient.\n",
    "## Disadvantage: Ignores word order and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752af66a-f365-47fd-aac4-d250ec1cc5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Vector: [2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentence = \"India will win T20 world cup, Go India.\"\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "filtered_tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]\n",
    "\n",
    "freq_dist = FreqDist(filtered_tokens)\n",
    "bow_vector = [freq_dist[word] for word in freq_dist]\n",
    "\n",
    "print(\"Bag-of-Words Vector:\", bow_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c173c-c4b1-4105-b115-0d822ad6b286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d84b7ee-8097-4dcf-9199-f5832bd6dfb8",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "## Overview: TF-IDF combines term frequency and inverse document frequency to assign weights to words. It reflects the importance of a word in a document relative to its importance across multiple documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bbc75-dfe6-4090-bbce-5ec561af74bf",
   "metadata": {},
   "source": [
    "## Methodology: Weighs the importance of each term based on its frequency in a document and across all documents.\n",
    "## When to Use: Information retrieval, document clustering.\n",
    "## Advantage: Considers term importance, reduces the impact of common words.\n",
    "## Disadvantage: Sparse representation, loses word order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bd127b-86ce-4443-a614-ebcabc6fcad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.         0.46941728 0.61722732 0.3645444  0.         0.\n",
      "  0.3645444  0.         0.3645444 ]\n",
      " [0.         0.7284449  0.         0.28285122 0.         0.47890875\n",
      "  0.28285122 0.         0.28285122]\n",
      " [0.49711994 0.         0.         0.29360705 0.49711994 0.\n",
      "  0.29360705 0.49711994 0.29360705]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"TF-IDF Matrix:\")\n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a19792-f6e5-4334-98e4-2985f3be8804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f476c2c-6738-4f37-a2f1-a9de38709786",
   "metadata": {},
   "source": [
    "# CountVectorizer:\n",
    "## Overview: CountVectorizer converts a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338ed99-97a7-4170-bf37-ee09a9110334",
   "metadata": {},
   "source": [
    "## Methodology: Converts a collection of text documents to a matrix of token counts.\n",
    "## When to Use: Similar to BoW, commonly used in text processing tasks.\n",
    "## Advantage: Simple, effective for basic tasks.\n",
    "## Disadvantage: Ignores context and semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c32ddce-140b-4ecc-8ea5-753d5cb9ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Matrix:\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"CountVectorizer Matrix:\")\n",
    "print(count_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afc111-45ed-4a24-9966-991cbb99c394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59e8b12-626c-4678-80f0-3c6a97c8de9a",
   "metadata": {},
   "source": [
    "# Co-Occurrence Vectors\n",
    "## Co-occurrence vectors represent the relationships between words based on their co-occurrence patterns in a given context, such as a document or a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a1147-bef9-4be5-ab43-42a53a8d5509",
   "metadata": {},
   "source": [
    "## Methodology: Represents words based on their co-occurrence with other words in a given context.\n",
    "## When to Use: Capturing semantic relationships between words.\n",
    "## Advantage: Captures semantic meaning.\n",
    "## Disadvantage: Requires large amounts of data, computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3fed980-0e1e-4a18-9169-f51efadba622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-Occurrence Matrix:\n",
      "[[1 1 0 1 0 1 0 1 0 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 0 1 0 1]\n",
      " [0 0 1 0 1 1 0 1 1 0 1 0]\n",
      " [1 1 0 1 0 1 0 1 0 1 0 1]\n",
      " [0 0 1 0 2 1 1 1 2 0 2 0]\n",
      " [1 1 1 1 1 2 0 2 1 1 1 1]\n",
      " [0 0 0 0 1 0 1 0 1 0 1 0]\n",
      " [1 1 1 1 1 2 0 2 1 1 1 1]\n",
      " [0 0 1 0 2 1 1 1 2 0 2 0]\n",
      " [1 1 0 1 0 1 0 1 0 1 0 1]\n",
      " [0 0 1 0 2 1 1 1 2 0 2 0]\n",
      " [1 1 0 1 0 1 0 1 0 1 0 1]]\n",
      "Co-Occurrence Vector for 'natural': [0. 0. 1. 0. 2. 1. 1. 1. 2. 0. 2. 0.]\n",
      "Co-Occurrence Vector for 'language': [0. 0. 1. 0. 2. 1. 1. 1. 2. 0. 2. 0.]\n",
      "Co-Occurrence Vector for 'processing': [0. 0. 1. 0. 2. 1. 1. 1. 2. 0. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"I love natural language processing.\",\n",
    "    \"Natural language processing involves machine learning.\",\n",
    "    \"Machine learning is a subfield of artificial intelligence.\"\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer to build the co-occurrence matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Get the vocabulary and co-occurrence matrix\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "co_occurrence_matrix = X.T.dot(X)\n",
    "\n",
    "# Display the co-occurrence matrix\n",
    "print(\"Co-Occurrence Matrix:\")\n",
    "print(co_occurrence_matrix.toarray())\n",
    "\n",
    "# Create co-occurrence vectors for specific words (e.g., 'natural', 'language', 'processing')\n",
    "words_to_find = ['natural', 'language', 'processing']\n",
    "co_occurrence_vectors = np.zeros((len(vocabulary), len(words_to_find)))\n",
    "\n",
    "for i, word in enumerate(words_to_find):\n",
    "    index = np.where(vocabulary == word)[0][0]\n",
    "    co_occurrence_vectors[:, i] = co_occurrence_matrix[:, index].toarray().flatten()\n",
    "\n",
    "# Display the co-occurrence vectors\n",
    "for i, word in enumerate(words_to_find):\n",
    "    print(f\"Co-Occurrence Vector for '{word}':\", co_occurrence_vectors[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39470c9-4563-44eb-a5a6-5ddf42af6e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00c2ea50-9109-4240-8e63-74f2841e9959",
   "metadata": {},
   "source": [
    "# Word Embeddings with Word2Vec:\n",
    "## Overview: Word2Vec is a popular word embedding technique that represents words as vectors in a continuous vector space. It captures semantic relationships between words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d70e13-1fe8-446b-8a0a-90fb26c38f04",
   "metadata": {},
   "source": [
    "## Methodology: Neural network-based model that learns continuous vector representations of words.\n",
    "## When to Use: Word similarity, analogy, language translation.\n",
    "## Advantage: Captures semantic relationships, context-aware.\n",
    "## Disadvantage: Training can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe689f9-ed86-410c-95b0-af1a71043aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Vector for 'example': [-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
      "  4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
      "  6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
      "  3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
      "  8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
      "  1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
      " -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
      "  2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
      " -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
      "  9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
      "  3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
      "  7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
      " -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
      " -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
      "  1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
      "  2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
      "  4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
      " -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
      " -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
      " -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
      " -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
      " -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
      " -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
      " -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
      "  5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentence = \"Word embeddings example using Word2Vec.\"\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "\n",
    "model = Word2Vec([tokens], vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_vector = model.wv['example']\n",
    "\n",
    "print(\"Word2Vec Vector for 'example':\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429a6e1-89c8-458b-89b7-5ad6a762c973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd3b5104-4f0b-432b-9848-3e67a264da0c",
   "metadata": {},
   "source": [
    "# Doc2Vec:\n",
    "## Create fixed-size vector representations for entire documents or paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb29e9-8bf4-48cb-9833-c5401ee9174d",
   "metadata": {},
   "source": [
    "## Methodology: Extends Word2Vec to learn vector representations for entire documents.\n",
    "## When to Use: Document-level tasks, similarity analysis.\n",
    "## Advantage: Represents document semantics.\n",
    "## Disadvantage: Requires large datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a34a66-4219-4ce7-a2a6-61f187b01139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Abhishek_Jaiswal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred Vector for the New Document:\n",
      "[ 0.00913433 -0.01606776  0.00786865 -0.00168634 -0.00616813 -0.02438825\n",
      " -0.02970823 -0.00117354 -0.01100831  0.00757701 -0.00217394  0.02749209\n",
      " -0.0086424   0.01498963 -0.00889873 -0.01935071  0.0215288  -0.01420226\n",
      "  0.00585465  0.01771524]\n",
      "\n",
      "Similar Documents:\n",
      "Document 1: Similarity = 0.24449604749679565\n",
      "Document 0: Similarity = 0.2404424548149109\n",
      "Document 2: Similarity = 0.01952333375811577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\Temp\\ipykernel_4920\\1249084438.py:27: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  similar_documents = model.docvecs.most_similar([new_vector])\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"This is an example sentence for document 1.\",\n",
    "    \"Another document for training Doc2Vec.\",\n",
    "    \"Doc2Vec embeddings capture document semantics.\"\n",
    "]\n",
    "\n",
    "# Tokenize and tag documents\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
    "\n",
    "# Train Doc2Vec model\n",
    "model = Doc2Vec(vector_size=20, window=2, min_count=1, workers=4, epochs=100)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Infer vector for a new document\n",
    "new_document = \"A completely new document for testing.\"\n",
    "new_vector = model.infer_vector(word_tokenize(new_document.lower()))\n",
    "\n",
    "# Find similar documents\n",
    "similar_documents = model.docvecs.most_similar([new_vector])\n",
    "\n",
    "# Display results\n",
    "print(\"Inferred Vector for the New Document:\")\n",
    "print(new_vector)\n",
    "\n",
    "print(\"\\nSimilar Documents:\")\n",
    "for doc_id, similarity in similar_documents:\n",
    "    print(f\"Document {doc_id}: Similarity = {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872f70e-8cd1-4ac4-88ca-903fb5ef4fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "047e6e38-979b-4aec-b190-be84e1a74ec1",
   "metadata": {},
   "source": [
    "# GloVe (Global Vectors for Word Representation):\n",
    "## Overview: GloVe is an unsupervised learning algorithm that learns vector representations for words by considering global word co-occurrence statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67da093-5f9b-48dc-bf55-3e37f7145ee2",
   "metadata": {},
   "source": [
    "## Methodology: Factorizes the word co-occurrence matrix to obtain word vectors.\n",
    "## When to Use: Similar to Word2Vec, capturing word semantics.\n",
    "## Advantage: Captures global context, computationally efficient.\n",
    "## Disadvantage: Less flexible than Word2Vec in some contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f369db-c699-4bd3-9802-e54e81a31a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Download GloVe embeddings (50-dimensional vectors)\n",
    "#glove_model = KeyedVectors.load_word2vec_format('path/to/glove.6B.50d.txt', binary=False)\n",
    "\n",
    "#word_vector = glove_model['example']\n",
    "#print(\"GloVe Vector for 'example':\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f468d4-0c07-4c45-b472-83997907d706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b770d73-567b-4e72-8828-c9b0b951e216",
   "metadata": {},
   "source": [
    "# FastText:\n",
    "## Overview: FastText is an extension of Word2Vec that considers subword information. It is capable of handling out-of-vocabulary words by breaking them into subwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840f114-ad2b-4103-bdf0-41f4f6dd1ea8",
   "metadata": {},
   "source": [
    "## Methodology: Extension of Word2Vec that considers subword information.\n",
    "## When to Use: Handles out-of-vocabulary words, morphologically rich languages.\n",
    "## Advantage: Captures subword information.\n",
    "## Disadvantage: Can be computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e52d033-9eda-4717-8968-25414b85891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText Vector for 'example': [-4.1726835e-05  1.0451592e-03 -7.9474889e-04 -1.3063694e-04\n",
      "  1.6382125e-03 -1.1647420e-04  2.4407771e-03  7.9540536e-05\n",
      "  1.3699072e-03 -1.8755053e-03  7.8245735e-05 -1.5996076e-04\n",
      " -8.3208835e-04  4.1482301e-04 -1.0503531e-03  7.2501454e-04\n",
      "  2.0358281e-03  6.8655162e-04  2.0658619e-04 -2.7593336e-04\n",
      " -1.1705712e-03 -1.1062991e-03  2.1329117e-03 -1.0457300e-03\n",
      "  4.7213794e-04 -8.8065921e-04 -1.1785245e-03  2.9314411e-05\n",
      "  1.4384058e-03 -2.2715896e-03  1.6475127e-03  7.0370216e-04\n",
      "  2.4665735e-05 -1.6384796e-03  3.5863672e-04  4.8421248e-04\n",
      " -6.1883865e-04  1.7340139e-03  5.8272568e-04 -1.4774782e-04\n",
      " -1.3303286e-03  3.9146931e-04 -1.3422145e-03  1.8008887e-04\n",
      " -2.2951538e-04  2.1031315e-03  2.6376569e-03  3.1128211e-04\n",
      " -9.9887443e-04 -1.5810255e-03  3.2167006e-03  2.3891455e-03\n",
      " -8.2253310e-04  1.0443755e-03 -7.4361201e-04 -6.5593526e-04\n",
      " -4.4622127e-04  1.9408112e-04 -1.9209203e-03  6.6872839e-05\n",
      " -2.2360731e-03  1.4354823e-03  5.5735483e-04 -1.7095894e-03\n",
      "  4.1400091e-04 -8.0396072e-04 -7.0638389e-06  5.7015446e-04\n",
      " -8.0505433e-04  1.9180265e-05  1.3083425e-04  7.1733026e-05\n",
      " -8.2741922e-04 -1.2827691e-03  6.5799453e-04  1.7979093e-05\n",
      " -2.5443905e-03 -1.2740159e-03 -1.2650233e-04 -9.7167405e-04\n",
      "  1.0447943e-03  9.6904568e-04  9.8297442e-04 -2.6767540e-03\n",
      " -6.4225896e-04 -1.2960396e-03  2.0127512e-04 -2.4758654e-03\n",
      "  9.0547686e-04 -1.4879610e-04  9.3658041e-04 -1.7016289e-03\n",
      " -3.9345407e-04 -3.7922233e-04 -3.6777451e-04 -1.0104489e-03\n",
      "  9.9095819e-04 -7.2503790e-05 -1.7997400e-04  4.9985297e-06]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentences = [\"FastText embeddings example.\", \"Another sentence for FastText example.\"]\n",
    "\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "fasttext_model = FastText(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "word_vector = fasttext_model.wv['example']\n",
    "print(\"FastText Vector for 'example':\", word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a0877-0762-4244-8c74-f6e806ff8762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94f84104-a57b-4fa1-9d4d-6889b3d84c4a",
   "metadata": {},
   "source": [
    "# Transformer-based Embeddings with BERT:\n",
    "## Overview: BERT (Bidirectional Encoder Representations from Transformers) is a transformer-based model that captures contextualized embeddings for words or sentences. It considers the entire context of a word in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3ca42-35be-43bf-8c2a-795f652addd6",
   "metadata": {},
   "source": [
    "## Methodology: Transformer-based model that considers bidirectional context for word representations.\n",
    "## When to Use: State-of-the-art for various NLP tasks.\n",
    "## Advantage: Captures contextual information, versatile.\n",
    "## Disadvantage: Computationally expensive, requires significant resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "575906c2-32ec-4d6b-aa5a-22ec93368ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "BERT Embedding: [-2.63572663e-01 -3.31556261e-01 -3.01078498e-01 -2.97505856e-01\n",
      "  1.86010420e-01 -4.19930100e-01  2.66853392e-01  3.45946759e-01\n",
      "  1.01733766e-01  1.82084683e-02 -1.78565651e-01 -7.12604970e-02\n",
      " -3.31277162e-01  1.06502905e-01 -1.56765878e-01  3.92356189e-03\n",
      " -3.00724804e-01  2.69849598e-01 -2.52546161e-01 -1.69669107e-01\n",
      "  1.49439067e-01  6.65292665e-02 -7.01846600e-01 -2.26758420e-02\n",
      "  7.61362493e-01  1.72867440e-02  2.83978749e-02 -2.72862911e-01\n",
      " -7.56983936e-01  2.45770529e-01  8.79423916e-02  3.43298703e-01\n",
      "  3.81972343e-02 -7.75864068e-03 -4.81050640e-01 -2.70018667e-01\n",
      "  4.49225843e-01 -1.39791787e-01 -7.96206072e-02  3.56219292e-01\n",
      " -6.02236748e-01 -4.13774520e-01  6.95797741e-01  1.60257313e-02\n",
      "  1.57124162e-01 -1.56724244e-01 -3.73370618e-01 -8.48812684e-02\n",
      "  5.70420437e-02 -1.13121934e-01 -7.98189402e-01  2.66736805e-01\n",
      "  1.56094670e-01  3.93177629e-01  1.45533696e-01  2.94677317e-01\n",
      "  4.05181646e-01 -6.90931559e-01  1.79678217e-01 -1.52262211e-01\n",
      "  4.06807989e-01  3.76875639e-01 -7.16769993e-02 -4.04710740e-01\n",
      "  4.93919313e-01  2.16433018e-01 -3.53765115e-02  4.95709956e-01\n",
      " -9.33993042e-01  1.04144797e-01 -4.53730464e-01 -2.87004739e-01\n",
      "  1.12834483e-01 -2.00426504e-01  7.52522796e-02  1.66828588e-01\n",
      " -3.35363746e-01  1.66696236e-01  6.99868873e-02 -6.65798426e-01\n",
      " -2.22674429e-01  4.27838266e-01 -1.12783343e-01  7.69187286e-02\n",
      "  5.23259997e-01  2.72450317e-02  9.86794196e-03  3.21803898e-01\n",
      " -6.57055855e-01  5.17990351e-01  1.00904413e-01 -6.00914896e-01\n",
      " -2.89667964e-01  1.27787873e-01  6.26132250e-01  2.46453390e-01\n",
      " -4.43787605e-01  1.08981542e-01  7.12207630e-02  3.91834795e-01\n",
      "  8.37938860e-02 -5.35214663e-01  2.90673673e-01  2.17969909e-01\n",
      " -3.51413459e-01 -2.17700213e-01 -1.89178675e-01  5.52929163e-01\n",
      "  6.69197142e-02  1.11885108e-01  1.61790922e-01 -2.55877703e-01\n",
      "  3.59364510e-01  1.92060822e-03 -3.10007721e-01  3.17789316e-01\n",
      " -2.00178117e-01  6.62794784e-02  5.25689423e-02 -6.81179225e-01\n",
      "  1.19101629e-01  2.23529547e-01  2.14816779e-01  1.27926528e+00\n",
      " -1.08801477e-01  6.06052339e-01 -2.44114637e-01  7.86365569e-01\n",
      "  4.14788187e-01  1.50368631e-01  2.22678320e-03  4.14396584e-01\n",
      "  6.76149607e-01 -1.48185506e-01 -7.19022453e-02  1.81532681e-01\n",
      " -3.67240906e-01 -8.32683444e-02 -4.40855682e-01 -1.63976215e-02\n",
      " -3.09357464e-01  3.76277387e-01  4.52500671e-01 -8.60044137e-02\n",
      "  7.14301646e-01  1.91958115e-01 -1.72654465e-01 -1.91634461e-01\n",
      "  2.28991106e-01  6.53424501e-01  9.84856188e-02  3.05568755e-01\n",
      " -5.45023739e-01 -2.62290478e-01 -6.20971501e-01 -7.74708018e-02\n",
      "  3.01915675e-01  3.00871193e-01  5.04326969e-02  2.20731974e-01\n",
      "  8.34504545e-01  3.85660559e-01  4.24541347e-02  2.39665452e-02\n",
      "  9.84412059e-02 -8.22752342e-03 -5.46160564e-02  3.52615237e-01\n",
      "  3.81868752e-03  6.77221715e-02 -3.50920439e-01  6.83247745e-02\n",
      "  2.93912172e-01 -1.63507536e-01 -3.08584988e-01  3.23829740e-01\n",
      "  2.65469521e-01 -1.92426071e-01  2.84249932e-01  2.90772319e-02\n",
      " -1.40204704e+00  3.76383007e-01  9.75934565e-02 -3.80390882e-01\n",
      "  1.42389715e-01  1.06157452e-01  3.19186859e-02 -5.67773998e-01\n",
      " -1.02911722e-02 -3.08788329e-01 -2.82296985e-01 -6.39116108e-01\n",
      " -5.61108649e-01 -3.24052840e-01  5.88697910e-01 -3.89337093e-01\n",
      " -2.33444154e-01 -2.07016602e-01  4.98290546e-03 -4.34669316e-01\n",
      "  1.74532622e-01 -2.08807260e-01  2.06879154e-02 -3.77787799e-02\n",
      "  5.43419681e-02  3.17405224e-01 -7.04578403e-03 -3.63222122e-01\n",
      " -4.24854219e-01  3.22275788e-01 -4.05099541e-01  9.83175039e-01\n",
      "  2.99626976e-01 -1.06213884e-02  1.12626232e-01 -7.00121606e-03\n",
      "  4.12859954e-02 -3.06414992e-01 -3.22056830e-01  4.89874482e-02\n",
      " -3.35333675e-01 -7.22687542e-02 -7.31029749e-01 -4.49319072e-02\n",
      " -6.20993733e-01  8.14279139e-01  1.07131429e-01 -2.31161863e-01\n",
      "  4.63850021e-01  1.46760195e-01  2.73704052e-01 -1.74147785e-01\n",
      "  1.74171716e-01 -1.80406775e-02 -1.22899361e-01  3.57151210e-01\n",
      " -3.17906708e-01  8.24934766e-02 -8.14740136e-02  1.77210227e-01\n",
      " -2.19253942e-01  4.50418621e-01  5.22889853e-01 -4.42097396e-01\n",
      " -2.22536534e-01 -4.19450402e-01  3.49960029e-02  3.68826866e-01\n",
      "  5.42685568e-01 -7.54921377e-01 -1.40682831e-01 -7.04476893e-01\n",
      "  5.48977107e-02 -6.44066095e-01 -4.42956835e-01  1.57147944e-01\n",
      " -3.95464182e-01 -2.21462220e-01 -2.08153233e-01  1.04388607e+00\n",
      "  1.34156331e-01  5.98882027e-02  1.20424427e-01  4.53853935e-01\n",
      " -6.70978785e-01 -3.11717391e-01 -7.81472549e-02  7.79871583e-01\n",
      "  9.25917208e-01  3.42631266e-02 -7.02270567e-01 -5.56903958e-01\n",
      " -3.57567638e-01  4.01361920e-02 -3.70471358e-01 -4.71934043e-02\n",
      " -1.88994616e-01  2.12819457e-01  1.23135537e-01 -6.44149855e-02\n",
      "  3.52725774e-01  5.08383691e-01  6.37064353e-02 -6.78242892e-02\n",
      " -5.46737760e-02 -4.76482242e-01 -3.95757407e-01 -5.69846481e-02\n",
      " -3.42694163e-01 -5.91874778e-01 -4.38492522e-02  3.69148672e-01\n",
      " -3.29200149e-01  1.39976609e-02  3.90729845e-01  4.84031320e-01\n",
      "  4.21804428e-01  1.25613451e-01 -2.99087912e-01 -8.24498475e-01\n",
      " -3.04661632e-01 -4.17717874e-01 -4.60855588e-02 -4.03112322e-02\n",
      " -3.14065516e-01  3.64799261e-01 -2.59791672e-01 -5.54650426e-01\n",
      " -2.83150387e+00 -7.55307078e-02 -1.69702098e-02 -3.65213752e-01\n",
      "  7.64528587e-02 -3.07955384e-01 -3.78197163e-01 -2.04490006e-01\n",
      " -3.08979571e-01  2.14661628e-01 -1.17976479e-01 -5.41823506e-01\n",
      "  2.90306639e-02  6.12552106e-01  2.51082271e-01  4.47332174e-01\n",
      " -3.02204657e-02  1.82500064e-01 -1.28410473e-01  2.63983101e-01\n",
      " -1.71105370e-01 -2.71122783e-01  1.42149046e-01 -2.50444710e-01\n",
      "  2.91465878e-01  1.44889317e-02 -7.18661547e-01  6.41201973e-01\n",
      " -3.69346350e-01 -6.08060718e-01  2.58558869e-01 -2.06916839e-01\n",
      "  5.48351288e-01  1.01623066e-01 -3.26058507e-01  3.07663560e-01\n",
      "  1.45304307e-01  4.70983721e-02  2.21157849e-01 -4.94168878e-01\n",
      " -6.18908973e-03  4.54698622e-01  1.84607834e-01 -1.86805695e-01\n",
      "  5.06289601e-01 -6.19920015e-01 -1.64245039e-01 -4.82176036e-01\n",
      "  3.04241270e-01  1.38888195e-01 -4.02760148e-01 -2.12674990e-01\n",
      " -1.89836845e-02 -3.38858008e-01 -6.68508634e-02 -2.39790857e-01\n",
      "  1.81313008e-01  3.90541136e-01 -2.87630886e-01  4.96472605e-02\n",
      "  6.47842705e-01 -3.60125333e-01  2.59758085e-01 -1.21729016e-01\n",
      " -3.79739195e-01 -2.62200892e-01 -5.77896774e-01 -9.19537023e-02\n",
      " -5.27427375e-01  2.74698377e-01 -6.70305431e-01  5.60923032e-02\n",
      " -3.56872231e-01 -9.85259473e-01  2.94250041e-01 -2.68201768e-01\n",
      " -1.19289674e-01 -6.10662699e-01  1.38584167e-01 -2.88687110e-01\n",
      " -5.22656083e-01 -7.47749686e-01  3.16043198e-01 -4.47780043e-02\n",
      "  9.81365144e-02  6.53464854e-01  1.66055679e-01 -2.87886739e-01\n",
      "  7.53319561e-02 -2.10524499e-01 -2.88111554e-03  5.01370490e-01\n",
      "  2.27473557e-01  4.40184951e-01  8.76156092e-02  1.66644543e-01\n",
      "  6.14281535e-01 -5.88108599e-01  4.60350871e-01 -1.70977458e-01\n",
      "  6.70120046e-02 -1.85006678e-01  3.30758035e-01 -8.74640793e-02\n",
      " -3.21520925e-01  3.31449568e-01 -1.06693375e+00  1.08623005e-01\n",
      "  8.20340738e-02  5.08445390e-02  2.92573363e-01 -6.22734092e-02\n",
      "  4.23807532e-01 -2.62833118e-01 -4.58733767e-01  5.97598135e-01\n",
      "  7.99469799e-02  4.13731217e-01  4.75284517e-01 -1.08078450e-01\n",
      "  1.64772142e-02  7.07498193e-01 -4.01167750e-01 -3.41810644e-01\n",
      " -4.10922110e-01 -2.87218034e-01 -1.05956003e-01  2.16030598e-01\n",
      " -1.62423581e-01 -3.74017656e-01 -3.24405968e-01 -1.32858470e-01\n",
      " -5.52968048e-02  2.08070084e-01  2.85808623e-01 -7.89395034e-01\n",
      "  9.17833522e-02  5.76022863e-01  3.15901250e-01  5.37434742e-02\n",
      "  1.89620554e-01  3.61642897e-01  3.82570773e-02 -8.09985250e-02\n",
      " -3.05177182e-01  6.15345716e-01 -9.41661224e-02  6.47975951e-02\n",
      "  2.70214468e-01  4.49911738e-03 -2.74973381e-02 -2.22501218e-01\n",
      " -9.39892419e-03 -5.21626532e-01 -2.17867866e-02 -1.83660135e-01\n",
      "  1.74635619e-01 -2.40278408e-01 -7.17739016e-02 -7.56800771e-01\n",
      "  2.36291945e-01  5.56798875e-01  4.56263334e-01  2.00319916e-01\n",
      " -8.67651869e-03  4.15385991e-01 -9.66471732e-02  3.75777297e-02\n",
      " -2.07014889e-01  1.26770958e-01 -2.83230990e-01 -3.77041608e-01\n",
      "  4.84163404e-01  9.83399302e-02  3.11310172e-01  6.51762962e-01\n",
      "  2.32333720e-01 -2.70520657e-01  4.89076614e-01  1.07749033e+00\n",
      "  4.06760186e-01  3.08590740e-01  1.63836420e-01 -2.86513180e-01\n",
      "  4.01301324e-01  5.08458495e-01 -5.62242568e-01  8.05436373e-02\n",
      "  1.70086309e-01  6.50991052e-02 -7.63003051e-01  6.53608665e-02\n",
      " -1.71819255e-01 -3.06111783e-01 -5.36323726e-01 -2.38268435e-01\n",
      "  6.67751670e-01 -1.57657072e-01  2.83862829e-01 -2.99448967e-01\n",
      "  3.91402990e-01  1.22589916e-01 -4.46480066e-01 -7.33368099e-02\n",
      " -2.06866205e-01 -4.27804850e-02  2.27778971e-01 -2.06030652e-01\n",
      "  1.16802014e-01 -1.14195943e-01  2.13152140e-01 -5.37855208e-01\n",
      " -5.34698188e-01 -9.60617602e-01  5.26367724e-01 -2.97741629e-02\n",
      "  2.80826926e-01  4.57215160e-02 -2.78625965e-01 -2.59216636e-01\n",
      " -7.19180465e-01 -2.12266147e-01  1.91933334e-01  4.89951611e-01\n",
      " -3.99982303e-01  3.93372923e-02 -1.78879037e-01 -3.58334333e-01\n",
      " -9.55461264e-01 -8.06492567e-03  1.26718625e-01 -1.28686145e-01\n",
      " -4.43722531e-02  1.69517949e-01  2.66118377e-01 -2.24024773e-01\n",
      " -8.07171226e-01 -4.53958571e-01  1.54801115e-01 -7.95153856e-01\n",
      " -1.62947550e-01  1.08477557e-02 -8.85417163e-02 -7.79541790e-01\n",
      "  3.88752930e-02 -2.97985077e-01 -1.57952070e-01  6.09533012e-01\n",
      "  7.00652450e-02  5.93750834e-01 -2.21456572e-01  6.96825013e-02\n",
      " -2.08787933e-01 -1.94994152e-01  3.62603307e-01 -3.74606401e-01\n",
      " -5.06253779e-01 -2.08550960e-01 -6.91615462e-01  2.56826848e-01\n",
      "  3.22326213e-01 -3.20585310e-01 -4.54811513e-01  4.65389669e-01\n",
      "  4.62230563e-01  3.62143636e-01  1.89020962e-01  2.82997876e-01\n",
      "  2.93213904e-01 -3.32872361e-01 -4.87811148e-01  8.69282708e-03\n",
      "  4.48345184e-01  3.82973850e-02  6.38452768e-02 -5.58566570e-01\n",
      "  5.76175712e-02 -3.59811395e-01  2.19243094e-01  2.89709233e-02\n",
      "  9.05469358e-02 -1.33948261e-02 -1.40607208e-02  2.06679240e-01\n",
      "  4.36336517e-01 -1.94268540e-01 -4.42661762e-01 -9.56218913e-02\n",
      " -3.19448411e-02 -2.95565695e-01 -1.56597160e-02  3.05533141e-01\n",
      " -2.52868593e-01 -2.42126971e-01 -7.28460401e-02  5.73723376e-01\n",
      "  5.24045527e-01  1.29799217e-01 -2.80800499e-02  1.64769366e-02\n",
      " -1.67215049e-01  5.37632763e-01  2.58127660e-01  3.28971744e-01\n",
      " -5.18219113e-01  1.49754494e-01  7.20150769e-02 -3.17892879e-01\n",
      "  1.14639759e-01  4.47544307e-01 -2.21288249e-01 -2.89722741e-01\n",
      "  5.81453443e-01  5.99035144e-01 -5.13243139e-01 -3.47302616e-01\n",
      "  2.62691408e-01 -3.08586806e-01  1.40207171e-01  3.24482471e-02\n",
      " -1.95065346e-02 -1.94689408e-01  6.33617163e-01  1.30386904e-01\n",
      " -1.71388194e-01  5.46535075e-01 -3.04038465e-01 -1.36710882e-01\n",
      " -3.60168695e-01  1.53764457e-01  1.62893876e-01  1.46866873e-01\n",
      "  1.32346511e-01  4.47850078e-01 -4.76844937e-01 -4.04124141e-01\n",
      "  1.39358968e-01  3.76071304e-01  4.60265517e-01 -5.24533689e-01\n",
      "  3.16119373e-01  2.79611945e-01  1.03155207e-02 -8.25194567e-02\n",
      " -2.78586805e-01 -1.86633646e-01 -4.20365781e-02  2.17887744e-01\n",
      "  4.84248638e-01  9.97155190e-01  2.22586632e-01  1.54448345e-01\n",
      "  4.02585715e-02 -4.78099138e-01  1.13810696e-01  4.58150432e-02\n",
      "  6.27485514e-01  3.97308707e-01  6.91230744e-02  3.80543143e-01\n",
      "  4.14540946e-01  2.82560452e-03  4.79310080e-02 -6.34534121e-01\n",
      "  7.52077028e-02  3.55469286e-01  5.66965163e-01 -3.02646384e-02\n",
      " -9.31629837e-02 -4.41823490e-02 -1.40860736e-01  3.55014473e-01\n",
      "  1.78854048e-01  2.09315613e-01 -2.67261416e-01  3.59656930e-01\n",
      "  1.18447460e-01 -6.15015887e-02 -8.11584532e-01  4.17342074e-02\n",
      " -2.24520147e-01  1.66348312e-02 -2.72942901e-01 -2.92250097e-01\n",
      " -7.58531392e-02 -5.41272163e-01  1.65339574e-01 -8.02017152e-02\n",
      " -2.14092076e-01 -2.01052293e-01 -1.46887720e-01 -4.31744941e-03\n",
      "  6.14870787e-01 -3.14434111e-01  6.30354941e-01 -3.54205728e-01\n",
      " -2.06546649e-01  5.72211564e-01  5.31839609e-01 -1.38270110e-01\n",
      "  2.39108011e-01 -2.61046976e-01 -2.41158321e-01  1.70989349e-01\n",
      " -1.04012080e-01 -3.54799032e-02 -1.59283087e-01  2.91508168e-01\n",
      " -2.46757030e-01 -2.30743480e-03  5.01070559e-01  5.60243726e-01\n",
      " -8.36855650e-01 -2.90130705e-01 -1.55017510e-01  4.84390184e-02\n",
      "  4.14468125e-02  1.55288830e-01 -5.16992867e-01  4.53737855e-01\n",
      " -7.61510253e-01 -2.30467424e-01  3.88898790e-01  2.51213223e-01\n",
      " -8.94488990e-02  1.01379685e-01 -2.12026164e-01  4.09184337e-01\n",
      "  1.28426015e-01  2.57312328e-01  4.56049860e-01  3.15037400e-01\n",
      " -4.87977490e-02  2.67285705e-01  3.51145834e-01 -3.34150165e-01\n",
      " -2.62688547e-01  4.08111006e-01  1.56795800e-01  2.82002389e-01\n",
      " -6.11725926e-01  3.91508281e-01  1.80004254e-01  5.36176503e-01\n",
      " -9.63426590e-01  2.49038666e-01 -9.32866037e-02 -3.77202630e-01\n",
      " -5.11441886e-01 -3.01467478e-01  4.12133902e-01  9.20969248e-02\n",
      " -9.70446542e-02 -5.19672751e-01 -1.36004314e-01 -3.90880648e-03\n",
      "  4.04842496e-01 -2.53247499e-01 -3.62223357e-01  8.05341154e-02]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = \"BERT embeddings example.\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "outputs = model(input_ids)\n",
    "\n",
    "bert_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "print(\"BERT Embedding:\", bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844743f7-a74d-44fa-aacf-8cfdf6569ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09391ec6-2345-4e55-98c0-ab4e7882515d",
   "metadata": {},
   "source": [
    "# Sentence-BERT (SBERT):\n",
    "## Overview: SBERT is an extension of BERT designed to generate sentence embeddings. It utilizes a siamese network structure to learn sentence embeddings that capture semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a06a37-3162-4578-a9d5-ed36d8054755",
   "metadata": {},
   "source": [
    "## Methodology: Extends BERT to learn sentence embeddings.\n",
    "## When to Use: Similarity analysis, clustering at the sentence level.\n",
    "## Advantage: Captures contextual information for sentences.\n",
    "## Disadvantage: Computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a248930-ad74-4d4f-848a-4514ba9d1e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9011ad1f872c48b3893a8c674d8df211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39987b72aaa549ceb0b0609af40a92bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12cc8cda4e44f7c9669019c981d8ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f053a52183cb47128c68d9904399ee1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4fe036b9674896a381cc1bfe80015f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a079a13d542745468726e890985c1b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3471f0ec764686bf036dabf2900b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96790b674771422caca866b553a0381c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517b3fdb46d3464a9271f28058da4c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade24a3299464404981276d9d27749aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a93011ef924fd6b32911a7a6449bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e721a1cff994b5e8ec28a8a4204e7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Embeddings: [[-2.78134048e-01 -3.04168370e-02 -5.99764585e-02 -2.09489867e-01\n",
      "   2.54968349e-02 -8.34133774e-02  3.52608323e-01 -2.75598019e-01\n",
      "  -3.70376743e-02 -5.74031711e-01  1.86858475e-01  4.87667799e-01\n",
      "   1.38373464e-01 -2.16210052e-01  4.24110025e-01  4.66380358e-01\n",
      "   3.10919344e-01  1.08791995e+00 -5.53535402e-01 -3.52626622e-01\n",
      "   6.70206189e-01 -1.28353864e-01  5.05717192e-03  5.34965880e-02\n",
      "   2.68644780e-01  3.01326692e-01  2.43460566e-01 -1.01914689e-01\n",
      "   2.52551615e-01 -9.07370269e-01  1.31337419e-01 -1.81816176e-01\n",
      "  -4.57603782e-01  1.52548835e-01 -3.60934645e-01 -2.41186731e-02\n",
      "  -4.72432852e-01  7.16334939e-01 -3.93797338e-01 -2.12378904e-01\n",
      "  -2.57432550e-01  2.45000906e-02 -1.99959829e-01 -4.83026728e-02\n",
      "  -1.19714692e-01 -8.12361598e-01  6.46489039e-02 -8.89339894e-02\n",
      "   9.72957835e-02  2.26182155e-02  1.67141348e-01 -5.19643664e-01\n",
      "  -2.64014423e-01 -3.75751883e-01 -8.50868523e-02  3.49136829e-01\n",
      "   1.70415267e-01  3.77623230e-01  2.94291470e-02 -2.14277223e-01\n",
      "   2.55547225e-01 -4.13748354e-01 -7.74805471e-02  3.83351505e-01\n",
      "   2.82563213e-02 -3.02528441e-01 -9.76589974e-03  2.59761721e-01\n",
      "  -3.06781232e-01  3.14196855e-01 -1.86705783e-01 -1.08972238e-02\n",
      "  -3.99977267e-01  2.53183544e-01  3.40892136e-01  7.04853237e-02\n",
      "  -1.07050821e-01  4.76776898e-01  2.00366408e-01 -1.83459952e-01\n",
      "   6.66611865e-02 -4.74221289e-01 -6.62501514e-01  3.34777415e-01\n",
      "   8.16182271e-02  5.37612796e-01  8.33933353e-02 -7.56413519e-01\n",
      "   2.18172863e-01  3.71002704e-01 -3.87391090e-01 -3.24802339e-01\n",
      "  -6.38154745e-02 -1.72282904e-01  2.49985129e-01 -2.93751364e-03\n",
      "   1.16091846e-02  1.73054263e-01  3.14268917e-01  2.06096023e-01\n",
      "  -2.36781478e-01  1.16810188e-01 -2.72098303e-01  2.17166513e-01\n",
      "  -5.18592186e-02 -9.09086883e-01 -1.29177183e-01 -3.77535895e-02\n",
      "   4.88886014e-02 -5.70012808e-01  2.94614255e-01 -1.64905593e-01\n",
      "  -2.10835645e-03 -3.71949255e-01 -3.61310542e-01 -8.71094018e-02\n",
      "   1.18933938e-01 -3.32405031e-01 -3.67086738e-01 -3.57301503e-01\n",
      "   2.71680772e-01  8.12572986e-02 -2.69364774e-01  5.32613277e-01\n",
      "   2.24385053e-01 -1.17537595e-01  2.55908936e-01  1.11417271e-01\n",
      "   2.71268696e-01 -1.24000214e-01  2.26446107e-01 -9.66820866e-02\n",
      "   9.56852436e-01 -2.81215012e-01 -1.20175496e-01  1.70161221e-02\n",
      "  -2.38770127e-01 -1.75832838e-01 -2.16179088e-01  2.08075210e-01\n",
      "  -1.55437678e-01  4.76974428e-01  1.46648914e-01 -8.34981054e-02\n",
      "   2.57565044e-02  4.96461779e-01 -5.72790802e-01 -2.49831036e-01\n",
      "  -1.93319157e-01  2.12533712e-01 -2.89911449e-01 -6.00651324e-01\n",
      "  -3.56420487e-01 -1.32300407e-01  5.75862527e-01 -7.01267049e-02\n",
      "  -5.01204193e-01  3.49604487e-01  2.04294562e-01  4.00138348e-02\n",
      "   1.44514712e-02  6.83213234e-01 -2.95226462e-02 -2.30035037e-01\n",
      "   3.54911357e-01  1.25469357e-01  1.57046869e-01 -9.80784744e-02\n",
      "   2.57170618e-01 -4.12453301e-02 -5.37207544e-01  3.57565254e-01\n",
      "   2.10779160e-01 -2.94699401e-01  5.09613395e-01  4.72293466e-01\n",
      "   6.82855621e-02 -2.07097009e-02  1.37978941e-01  4.50591862e-01\n",
      "   3.80921513e-01 -4.12708849e-01  3.38645577e-01 -3.52761298e-01\n",
      "  -7.72343636e-01  1.31861791e-01  4.62714583e-02 -1.43721104e-01\n",
      "   1.24743246e-01  2.18179137e-01 -1.07045891e-02  2.31263310e-01\n",
      "  -2.80026972e-01  3.09564352e-01  1.44344628e-01 -4.21717484e-03\n",
      "   2.97239840e-01 -3.97414923e-01 -1.25479341e-01  1.51041478e-01\n",
      "  -4.85638231e-01 -3.67946118e-01  4.15706914e-03  8.75367075e-02\n",
      "  -5.67048900e-02  2.35004276e-01  1.59630895e-01 -9.94214416e-02\n",
      "  -8.37073982e-01 -2.48168468e-01  1.22404158e-01  7.64564574e-02\n",
      "   1.02771446e-01 -6.01516739e-02  1.75054938e-01 -7.59333968e-01\n",
      "  -3.60211998e-01  3.85898049e-03 -2.11997718e-01  1.14477038e-01\n",
      "   3.57897882e-03 -3.19762155e-02  7.31897533e-01 -3.19563210e-01\n",
      "  -1.13916561e-01  7.36523628e-01 -4.52473164e-01 -4.47001830e-02\n",
      "  -2.86027014e-01 -2.01751322e-01  4.98235762e-01 -1.49776489e-01\n",
      "  -9.34990309e-03 -1.77874967e-01 -5.24780869e-01  1.72889784e-01\n",
      "  -2.56016195e-01 -5.76870367e-02 -3.97052139e-01 -4.08868976e-02\n",
      "   2.17522711e-01 -1.89019740e-01 -1.88622341e-01 -1.60547316e-01\n",
      "  -1.17075481e-01  3.49757820e-01  5.07219315e-01  3.84646714e-01\n",
      "   7.85005745e-03  1.50692552e-01 -3.93067777e-01 -1.05043605e-01\n",
      "  -2.34836072e-01  1.32177323e-01 -3.51508141e-01  2.95135349e-01\n",
      "  -2.64046103e-01  2.89433777e-01 -9.40104485e-01 -2.25426815e-02\n",
      "   1.52754992e-01  3.36974114e-01  2.59840906e-01  4.41832155e-01\n",
      "   1.00199901e-01 -1.27831668e-01 -4.39948320e-01  2.31518030e-01\n",
      "  -4.17129844e-01 -1.59989387e-01 -2.75744975e-01 -1.86254442e-01\n",
      "   4.05689105e-02 -3.95415246e-01  8.04418325e-02  1.50172208e-02\n",
      "   4.30735767e-01 -1.01980828e-01  1.33484676e-01  1.32834941e-01\n",
      "   1.07981123e-01 -4.12353039e-01  1.08965710e-01  5.44465899e-01\n",
      "  -5.34959257e-01 -1.77564576e-01  3.93484980e-01  3.54590639e-02\n",
      "   3.95172417e-01 -8.24113935e-02  1.39391243e-01 -9.30664763e-02\n",
      "  -1.65649697e-01 -5.30052543e-01 -2.08125681e-01  2.22812802e-01\n",
      "  -3.66084784e-01  1.96958572e-01  3.25377792e-01 -1.48950621e-01\n",
      "  -7.44015798e-02  1.18685842e-01 -6.52130008e-01  2.45904371e-01\n",
      "  -3.77919793e-01 -2.84279376e-01  1.94920212e-01 -2.52910972e-01\n",
      "   1.41740486e-01 -6.04216695e-01 -3.55211854e-01  5.44497371e-01\n",
      "   1.04382321e-01  4.05567557e-01 -1.87479015e-02  5.72958350e-01\n",
      "  -1.02105878e-01  3.22461516e-01 -4.23629940e-01  4.47589964e-01\n",
      "  -3.18227112e-01 -2.44739622e-01 -2.55821086e-02 -2.77777106e-01\n",
      "   8.41902047e-02  5.85377701e-02  3.72011438e-02  2.43967816e-01\n",
      "  -1.36116371e-01 -5.03862679e-01  1.06616810e-01  2.35872716e-01\n",
      "  -2.59516180e-01  2.65716493e-01  3.83785546e-01 -3.78217369e-01\n",
      "   5.88874444e-02  2.10412025e-01 -4.50212002e-01 -3.61539200e-02\n",
      "  -3.03712666e-01  5.44104695e-01 -6.96999192e-01  4.92930472e-01\n",
      "   1.16509616e-01 -2.20260650e-01 -6.03312314e-01  5.06300807e-01\n",
      "   3.85683626e-01  1.52371582e-02  2.50138819e-01  6.33834064e-01\n",
      "   6.95964634e-01 -1.09365247e-01 -1.47828788e-01  6.53230846e-01\n",
      "   4.34963614e-01 -2.52541844e-02 -3.44179511e-01  9.92216229e-01\n",
      "  -4.68206815e-02 -2.02348620e-01 -1.34942517e-01  2.30840012e-01\n",
      "   1.45444451e-02  3.32543552e-01 -2.88699836e-01 -1.77973256e-01\n",
      "   4.38773870e-01  3.30066472e-01  1.05614342e-01  1.20038703e-01\n",
      "   1.54119581e-01  1.23379268e-01  1.26249298e-01 -1.69093281e-01\n",
      "   3.86630088e-01 -3.40601355e-01  3.03766906e-01  1.36362746e-01\n",
      "  -2.40239829e-01  3.66118103e-01  7.18968987e-01  1.58366874e-01]\n",
      " [-3.31902951e-02  3.75515461e-01  1.71580747e-01  1.35797942e-02\n",
      "  -3.40370685e-02 -1.68121099e-01  6.19056344e-01  9.21292752e-02\n",
      "   8.48795287e-03 -3.05346638e-01  2.99237251e-01  2.93070853e-01\n",
      "   1.24332666e-01 -2.84693837e-01  7.50771642e-01  2.72767663e-01\n",
      "   4.75939482e-01  6.50186658e-01 -5.01504660e-01 -1.92945421e-01\n",
      "   6.97892785e-01  4.42301929e-01 -1.31261069e-02  1.53666139e-01\n",
      "  -1.32336408e-01  5.10790408e-01  5.31338215e-01 -2.84764796e-01\n",
      "  -6.01626374e-02 -5.64151704e-01 -3.30867469e-01  1.41710341e-01\n",
      "  -2.89759994e-01 -2.07233429e-01 -4.88658279e-01  9.38902721e-02\n",
      "  -2.89329499e-01  9.02061224e-01 -2.34423410e-02 -2.39084348e-01\n",
      "  -1.30926490e-01 -1.81059062e-01  2.95747183e-02  1.33334681e-01\n",
      "  -5.18359601e-01 -6.46275461e-01  9.68513638e-02  1.00155964e-01\n",
      "   1.03846416e-01 -1.89060763e-01 -2.62941808e-01 -4.03361320e-01\n",
      "  -6.38732612e-02 -9.48505625e-02 -1.07067913e-01 -4.18008678e-03\n",
      "   4.87348884e-01  6.75284147e-01 -2.00865837e-03 -4.90169711e-02\n",
      "   7.69152418e-02 -5.36993928e-02 -5.52830815e-01  3.66074145e-01\n",
      "   5.20363688e-01 -5.02358615e-01  1.26884207e-01  1.29386038e-01\n",
      "  -3.43544841e-01  6.34406328e-01  3.91373830e-03  1.71339121e-02\n",
      "  -3.52613837e-01  4.02594894e-01 -6.81501254e-02 -3.44175220e-01\n",
      "   4.18303758e-01  4.73473608e-01  7.96217879e-04 -3.58844250e-02\n",
      "  -2.81767547e-01 -5.12314439e-01 -8.70889246e-01  2.50313014e-01\n",
      "  -4.18686628e-01  4.23747480e-01 -5.59213422e-02  3.03698387e-02\n",
      "   4.24522430e-01  2.03245714e-01 -6.06543183e-01  1.62500277e-01\n",
      "   4.37486917e-01 -4.99378085e-01  5.90682700e-02 -7.13069141e-02\n",
      "  -3.17037046e-01 -1.88317001e-01  1.15397282e-01  3.07079047e-01\n",
      "  -3.54649872e-02  2.32305691e-01 -5.18777847e-01  7.65416026e-02\n",
      "  -5.59077412e-02 -1.01725435e+00 -4.28697854e-01 -1.48666129e-01\n",
      "  -1.83555424e-01 -3.48895222e-01  1.41009003e-01 -2.46942937e-02\n",
      "   3.80532622e-01 -4.71653104e-01 -3.10345113e-01  7.77160078e-02\n",
      "  -2.74555862e-01 -8.47701654e-02 -1.51677996e-01 -3.80294710e-01\n",
      "   1.60713390e-01  2.70082414e-01 -7.10119784e-04  4.22893643e-01\n",
      "  -2.07391217e-01 -2.54342556e-01  2.52099305e-01  4.88090307e-01\n",
      "   2.36597359e-01  1.12915955e-01  1.22593932e-01 -4.61961418e-01\n",
      "   7.38643646e-01 -1.23493142e-01 -1.55071557e-01 -5.98496720e-02\n",
      "   2.85877377e-01  7.57084787e-02  5.42968333e-01  5.67406595e-01\n",
      "   2.47786179e-01  1.42237544e-01  1.29762635e-01  8.22529048e-02\n",
      "  -1.47211388e-01  7.26552725e-01 -3.09635282e-01 -3.27920288e-01\n",
      "  -5.66806272e-02  3.32493186e-01 -1.73295923e-02 -2.99807817e-01\n",
      "   1.75088450e-01 -5.81907511e-01  5.71722329e-01 -1.93705142e-01\n",
      "  -3.11882794e-01  3.99768353e-01  2.98884183e-01  3.00663590e-01\n",
      "  -1.15698166e-01  5.38846552e-01  2.96481520e-01 -6.97811842e-02\n",
      "   3.69910374e-02 -1.23935133e-01  2.19053879e-01 -2.76903778e-01\n",
      "   1.07747428e-02  5.99248074e-02 -1.96386084e-01  4.66468275e-01\n",
      "   1.01885401e-01 -2.88423538e-01 -8.84902030e-02  4.70204562e-01\n",
      "  -1.10130019e-01  9.93007347e-02 -1.76943749e-01  3.80674183e-01\n",
      "   2.92210042e-01 -5.54258585e-01  6.65868893e-02 -1.27721995e-01\n",
      "  -3.75828862e-01  4.03045863e-01 -9.46901143e-02 -4.98349816e-02\n",
      "   1.00342840e-01  2.46355325e-01 -3.19125533e-01  5.47752082e-01\n",
      "  -5.53530455e-01  2.03691944e-01 -4.70551401e-02  1.31915048e-01\n",
      "   6.18091285e-01 -5.83754241e-01 -3.08674812e-01  1.06955484e-01\n",
      "  -5.35440385e-01  4.25539948e-02  1.88100472e-01 -4.17397022e-02\n",
      "   2.79692322e-01  5.72819859e-02  9.44473892e-02 -5.61931193e-01\n",
      "  -5.74365377e-01 -4.95850444e-01  1.16718203e-01  3.35193515e-01\n",
      "   2.77567133e-02  2.31386259e-01  2.22512424e-01 -5.96894026e-01\n",
      "  -3.59918505e-01  1.18377239e-01 -4.94192004e-01 -1.06862664e-01\n",
      "  -1.48151978e-03 -1.40664116e-01  7.59721398e-01 -4.22016144e-01\n",
      "  -1.74449325e-01  3.86926442e-01 -3.33504319e-01 -9.71175730e-02\n",
      "   2.75791764e-01 -4.52571601e-01  1.16145439e-01 -2.15177387e-01\n",
      "   1.83698177e-01 -1.86310142e-01 -8.48824203e-01 -2.49274969e-01\n",
      "   2.32794154e-02 -2.11741954e-01 -2.93774337e-01 -9.13005248e-02\n",
      "   3.00512135e-01 -5.48821688e-01 -2.05323085e-01  1.50900200e-01\n",
      "  -6.63853064e-02  6.78250432e-01  1.33538067e-01  4.49914895e-02\n",
      "  -1.34208441e-01 -1.28339872e-01 -4.44148540e-01 -9.38141197e-02\n",
      "  -7.83322632e-01  4.61396635e-01 -6.14624619e-01  2.67938972e-01\n",
      "  -2.88351893e-01  3.77656579e-01 -9.93329048e-01 -2.24880874e-01\n",
      "   1.59750804e-01 -4.07511353e-01  2.26967946e-01  2.36050785e-01\n",
      "  -9.63362027e-03 -1.31629288e-01  1.44445211e-01 -2.69502223e-01\n",
      "  -7.96771109e-01 -4.02659953e-01 -4.80889529e-01 -4.94169563e-01\n",
      "   1.05380312e-01 -1.86064720e-01  1.28575657e-02 -1.00566231e-01\n",
      "   4.58807200e-01  1.68028072e-01  9.91070718e-02 -2.76838750e-01\n",
      "   4.96901572e-01 -8.73393774e-01 -1.96115375e-02  4.14796829e-01\n",
      "  -4.57979888e-01  1.11994162e-01  4.76916432e-01  3.35779548e-01\n",
      "   7.90296197e-01 -1.17223039e-01  6.87583014e-02 -7.90852010e-02\n",
      "  -1.21496439e-01 -7.53915548e-01 -2.45505897e-03  2.20861852e-01\n",
      "  -6.60505891e-01  5.58440626e-01  8.06445330e-02  1.09880954e-01\n",
      "   5.49633354e-02 -2.14258417e-01 -8.53819311e-01  3.98127586e-01\n",
      "  -5.44623137e-01 -2.87812740e-01 -3.84066850e-02 -2.84671523e-02\n",
      "  -4.44743037e-02 -2.94806361e-01 -4.91666466e-01  1.04628325e-01\n",
      "   1.86307564e-01  3.47889364e-01 -6.27446547e-02  4.49689537e-01\n",
      "  -1.88520968e-01 -9.63224024e-02 -3.86040330e-01  2.82133639e-01\n",
      "   2.43257046e-01 -2.59324908e-01  1.06448777e-01  3.00249066e-02\n",
      "   1.02110453e-01 -2.95530677e-01 -2.38161013e-01 -1.57461882e-01\n",
      "  -2.25760937e-01 -9.23060179e-02 -1.54186159e-01  4.53741223e-01\n",
      "   2.81711221e-01  1.02560006e-01  1.82598367e-01 -3.15439999e-01\n",
      "   3.74284387e-01 -1.00368023e-01 -6.92301989e-01  4.82393093e-02\n",
      "  -8.83427262e-02  6.69614911e-01 -3.87176841e-01  5.06513476e-01\n",
      "   8.71795714e-02 -1.08057514e-01 -1.05460897e-01  1.88435838e-01\n",
      "   1.61999762e-01  3.31270844e-01  1.74823105e-01  6.30372763e-01\n",
      "   8.02451432e-01 -5.27687788e-01  3.47664595e-01  3.00193757e-01\n",
      "   8.65130961e-01  2.25206614e-01  8.41085091e-02  7.01341212e-01\n",
      "   2.55680799e-01 -8.80138390e-03  1.81542218e-01  8.33078504e-01\n",
      "  -9.68146175e-02  1.46556199e-01 -5.17335951e-01 -3.92856568e-01\n",
      "  -2.97392905e-02 -3.17058749e-02  3.13966274e-02  1.44967973e-01\n",
      "   2.08917603e-01 -1.88994393e-01  2.69664407e-01  5.76748066e-02\n",
      "   4.21092063e-01 -2.17787892e-01 -2.56570131e-01  3.97543743e-04\n",
      "   6.08381629e-01  3.81175071e-01  6.78909659e-01 -1.69664267e-02]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "sentences = [\"SBERT embeddings example.\", \"Another sentence for SBERT example.\"]\n",
    "\n",
    "sbert_embeddings = model.encode(sentences)\n",
    "print(\"SBERT Embeddings:\", sbert_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e20f2-e7c2-4620-91bf-2b4127c990c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e3afcbb-0ffd-4292-86e1-77d5fdb00e02",
   "metadata": {},
   "source": [
    "# Universal Sentence Encoder (USE) - TensorFlow Hub:\n",
    "## The Universal Sentence Encoder provides pre-trained embeddings for sentences or short texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec40e7-c35f-43a2-a13a-bb3f084770e4",
   "metadata": {},
   "source": [
    "## Methodology: Embeds sentences into fixed-size vectors using a deep averaging network.\n",
    "## When to Use: Sentence-level tasks, semantic similarity.\n",
    "## Advantage: Efficient, captures semantic meaning.\n",
    "## Disadvantage: May not capture complex context as well as BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "061a2d95-9606-4fd4-9d7a-48b60fffc7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_estimator\\python\\estimator\\util.py:74: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\native_module.py:92: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\saved_model_module.py:40: The name tf.saved_model.constants.LEGACY_INIT_OP_KEY is deprecated. Please use tf.compat.v1.saved_model.constants.LEGACY_INIT_OP_KEY instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:120: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for Sentence 1: [ 6.23825677e-02  2.08217185e-02  3.80545994e-03  2.92493701e-02\n",
      " -7.32270256e-02 -1.97310396e-03 -1.66500621e-02  3.30244526e-02\n",
      "  6.92790141e-03  5.26215322e-02 -1.02989255e-02 -1.13194976e-02\n",
      " -6.23090053e-03  1.00084148e-01  1.80095788e-02 -9.93793383e-02\n",
      " -1.39244348e-02 -1.76650397e-02 -4.52030301e-02 -5.56311309e-02\n",
      "  7.91292191e-02  3.78863327e-02 -1.52981188e-02 -5.07256621e-03\n",
      " -5.49593009e-02  7.23988712e-02  2.90205423e-02 -5.82795814e-02\n",
      " -5.40222926e-03 -1.69341322e-02  2.15250496e-02  8.37892015e-03\n",
      "  5.60170691e-03 -1.65353399e-02 -9.10105258e-02 -2.74207182e-02\n",
      "  5.25665618e-02  7.65372487e-03  6.13682147e-04 -2.69717146e-02\n",
      "  4.83603496e-03  2.30624042e-02  6.15627244e-02  7.88372904e-02\n",
      " -5.29996455e-02 -3.27655710e-02  2.29131859e-02 -2.13253815e-02\n",
      " -2.20250729e-02  1.78519897e-02  2.50901114e-02 -6.34129271e-02\n",
      " -1.00854225e-01 -1.90066118e-02 -2.80478578e-02 -1.85554624e-02\n",
      " -6.91876933e-02  3.61712649e-02 -5.96616305e-02 -3.40971164e-02\n",
      "  8.63478519e-03 -5.85589781e-02 -1.52278291e-02 -6.59579271e-03\n",
      " -3.83306034e-02 -3.74808423e-02 -2.91460678e-02  2.37150881e-02\n",
      "  2.72535719e-02 -6.02632985e-02 -6.03525760e-03 -4.13849354e-02\n",
      "  4.69958112e-02 -3.78393978e-02  3.08007952e-02 -3.71384583e-02\n",
      " -8.70216340e-02  4.17067818e-02  4.37714905e-03  2.22980306e-02\n",
      "  5.40862009e-02  1.31200915e-02 -4.75407131e-02  2.03986131e-02\n",
      "  1.16392551e-02  2.70418655e-02  4.57273237e-02 -6.15392141e-02\n",
      " -5.67844622e-02 -5.53921200e-02  5.27371503e-02  6.91324919e-02\n",
      " -2.23565679e-02  5.82477376e-02  1.15093431e-02  5.23094386e-02\n",
      " -1.14395320e-01  6.93153068e-02 -8.65997048e-04 -7.31357709e-02\n",
      "  4.45121937e-02  9.40018706e-03 -2.91012190e-02 -3.41592953e-02\n",
      " -4.42544669e-02  1.14765652e-02 -5.66199720e-02  1.45869721e-02\n",
      " -2.21870821e-02 -1.06979711e-02 -1.40910875e-02  5.36944866e-02\n",
      "  7.52648106e-03 -4.13211482e-03 -2.50449460e-02 -2.88422853e-02\n",
      "  8.88635404e-03  4.43882833e-04  4.41893525e-02  2.48533278e-03\n",
      "  2.43759379e-02  5.67101166e-02  3.29785491e-03 -3.15198973e-02\n",
      " -1.96262859e-02  5.42539284e-02 -3.08930334e-02 -1.78898554e-02\n",
      " -3.20765674e-02 -2.13612095e-02 -1.26016997e-02 -2.15702262e-02\n",
      "  5.50319701e-02 -1.70272812e-02  9.80940461e-03 -5.88872060e-02\n",
      "  5.04215211e-02 -4.16488945e-02 -1.12245895e-01 -2.62245573e-02\n",
      "  2.89784446e-02 -7.80809671e-02  2.71648187e-02 -3.29997092e-02\n",
      "  1.65207114e-03 -1.27171120e-02  3.70117314e-02 -1.23389941e-02\n",
      "  2.62708385e-02 -5.80377840e-02  3.11209727e-02 -9.28187668e-02\n",
      " -2.32144613e-02 -3.27521078e-02 -4.46999632e-03 -8.76155347e-02\n",
      "  7.07036331e-02  5.97794242e-02  3.63259614e-02  4.75816205e-02\n",
      " -4.42234054e-02  4.28709351e-02  3.83014344e-02  7.23580718e-02\n",
      " -5.59883974e-02  3.66498716e-02 -1.65054034e-02  1.42203514e-02\n",
      " -2.91585829e-02 -8.35682545e-03 -3.69251817e-02  6.90742806e-02\n",
      " -1.37043949e-02  1.93594513e-03  4.62967232e-02  4.83123139e-02\n",
      "  8.01906586e-02  6.81263506e-02  1.42192487e-02  4.56327535e-02\n",
      " -1.18857180e-03  5.05040865e-03  1.48907145e-02  3.18881162e-02\n",
      "  4.69878055e-02  2.38163788e-02  2.70157028e-02  6.41725436e-02\n",
      " -4.95416187e-02  2.70720050e-02 -1.15916627e-02 -2.27922411e-03\n",
      "  3.09494641e-02  2.70699081e-03  1.22033870e-02 -6.15285076e-02\n",
      "  1.73878632e-02  5.25617413e-02  1.35149211e-02  9.72108841e-02\n",
      " -1.02167934e-01  2.64548752e-02  7.23763695e-03  2.30704732e-02\n",
      "  3.49943265e-02  1.34311337e-02  7.91392773e-02 -1.52070085e-02\n",
      " -2.36263257e-02 -2.88418382e-02 -8.01017955e-02 -3.29978280e-02\n",
      " -8.21099430e-02  3.72376405e-02 -3.78000997e-02 -3.99709977e-02\n",
      "  2.37976983e-02  1.06628053e-02  6.66094944e-02 -3.47347511e-03\n",
      "  1.46508142e-02 -1.70010584e-03 -7.99585506e-03 -1.66435749e-03\n",
      " -3.81975845e-02 -7.25220889e-02  7.08252052e-03 -4.34858315e-02\n",
      "  2.42316239e-02 -3.79958712e-02 -4.67476733e-02  5.34440465e-02\n",
      "  1.81215797e-02  1.13475315e-01  5.84670231e-02  1.47726089e-02\n",
      "  1.13041013e-01  3.17997183e-03  3.68797928e-02 -5.32135786e-03\n",
      " -2.68098060e-02 -2.69265156e-02  3.45529206e-02 -5.03530763e-02\n",
      " -4.69966838e-03 -2.78461780e-02 -2.76405774e-02  1.84753872e-02\n",
      "  1.01967044e-01  6.43095821e-02 -3.98912765e-02 -5.47585115e-02\n",
      " -4.57108766e-02  4.16740449e-03  1.07525364e-01 -1.10838056e-01\n",
      " -3.53628770e-04  9.97921266e-03 -2.64642518e-02 -1.66668855e-02\n",
      " -1.99606642e-02  1.00114405e-01 -2.23438032e-02  3.66718136e-02\n",
      " -3.36985849e-03 -1.75387145e-03  6.72835633e-02 -9.78366658e-02\n",
      " -4.90067825e-02 -1.30411340e-02  4.23954725e-02  2.39704195e-02\n",
      " -3.48784141e-02  5.70740588e-02  2.21200176e-02 -3.17415223e-02\n",
      "  1.40330866e-02 -1.94030087e-02  4.59802076e-02 -5.93822636e-02\n",
      "  4.78002727e-02 -6.49288967e-02  7.11185392e-03  4.20737080e-02\n",
      " -5.66235918e-04  6.24101423e-02  3.99370007e-02  8.44631940e-02\n",
      " -6.11601807e-02 -1.62141267e-02 -4.23266599e-03 -7.12155104e-02\n",
      " -5.01690917e-02 -2.90881600e-02 -8.30424055e-02 -1.82492919e-02\n",
      " -2.81341430e-02  6.77853972e-02 -4.96065095e-02 -1.67025160e-02\n",
      "  5.33598959e-02  3.61588299e-02 -7.02094927e-04 -6.41585588e-02\n",
      "  2.01421604e-02 -6.44681379e-02  1.69041716e-02 -1.82671882e-02\n",
      " -3.39923091e-02 -3.00974138e-02 -5.44744320e-02  2.26934105e-02\n",
      " -2.96974778e-02 -1.87560904e-03  3.55568081e-02  4.04428728e-02\n",
      "  2.18950100e-02 -2.07250635e-03 -8.37867893e-03  2.16031866e-03\n",
      " -7.02348351e-03 -3.39121222e-02  3.81643176e-02  1.60197578e-02\n",
      " -5.14123240e-04 -3.91276851e-02  1.28444098e-02  6.49265870e-02\n",
      " -5.43945516e-03 -2.73118243e-02 -3.81706795e-03  4.10781335e-03\n",
      " -5.40497862e-02 -6.83076978e-02  4.29367982e-02 -6.97135041e-03\n",
      " -3.99091430e-02  5.63842105e-03  2.96888426e-02  1.81272328e-02\n",
      "  6.80980980e-02  6.76976666e-02  4.64395061e-03 -8.28016326e-02\n",
      " -6.66602105e-02 -3.23572047e-02  6.98944777e-02  3.02900821e-02\n",
      " -3.82972583e-02  6.40588179e-02 -2.03714333e-02  1.96078955e-03\n",
      "  4.26210016e-02 -3.40910293e-02  3.03326882e-02 -1.92524251e-02\n",
      " -9.83220637e-02  1.62386056e-02 -4.18580025e-02 -6.13427442e-03\n",
      " -8.63818377e-02  1.29944682e-02 -9.38542113e-02  1.42887663e-02\n",
      " -9.35092289e-03  5.87096661e-02 -4.77244593e-02 -3.50595801e-03\n",
      " -2.97783818e-02 -3.23377997e-02  2.71882769e-02 -3.82650271e-02\n",
      "  1.26274973e-02  7.22409114e-02  4.38222848e-02 -5.93913123e-02\n",
      "  7.17199687e-03  1.75594725e-02 -9.16335285e-02 -1.60763226e-02\n",
      "  1.03580831e-02 -8.44490677e-02 -6.45482317e-02  7.14825168e-02\n",
      " -2.16838121e-02 -1.25946281e-02 -6.31966144e-02 -8.49529263e-03\n",
      " -3.81060615e-02  2.66866609e-02  4.83593754e-02  1.11937113e-02\n",
      "  1.83709264e-02  3.16637743e-05  3.91930662e-04  1.76383294e-02\n",
      "  1.18901683e-02  1.75963938e-02  1.88483410e-02 -8.79223645e-02\n",
      " -3.83471847e-02 -2.58806869e-02 -2.96251941e-02 -2.43328791e-03\n",
      " -2.79900022e-02 -1.73836127e-02 -4.39386144e-02 -5.24466038e-02\n",
      "  1.64227840e-02  8.00833106e-02  1.97291616e-02  2.13681459e-02\n",
      "  6.98333904e-02 -5.65216951e-02  6.60862476e-02  4.91679006e-04\n",
      " -1.40220311e-03  5.69982044e-02 -5.30127855e-03 -3.22916843e-02\n",
      " -6.72638416e-04 -2.12755036e-02  5.71567193e-02 -6.50708750e-02\n",
      " -5.68491109e-02 -1.59892160e-02  1.08222701e-02  4.59220111e-02\n",
      " -5.98635972e-02  5.56873754e-02 -4.12939303e-02 -6.37277123e-03\n",
      "  6.96589947e-02  6.30236417e-03  5.28475493e-02 -1.06419288e-02\n",
      "  3.25633697e-02  3.80842760e-02  3.84659655e-02 -5.91476411e-02\n",
      " -1.72311384e-02 -8.43891799e-02 -1.96786155e-03 -5.54680713e-02\n",
      "  3.41282822e-02  1.47231445e-02 -9.82380472e-04 -4.06172797e-02\n",
      "  4.14760187e-02 -8.09946656e-03 -2.37115957e-02 -1.16591956e-02\n",
      " -3.45350220e-03 -1.87249631e-02  4.22861762e-02  6.02087332e-03\n",
      "  1.87834799e-02  8.76588225e-02  6.59520319e-03  1.13211209e-02\n",
      "  2.31099688e-02 -1.17733125e-02 -4.65935692e-02  3.92839536e-02\n",
      " -1.96220609e-03 -1.10078089e-01 -2.92100497e-02  4.00700681e-02\n",
      " -3.73510122e-02  9.49352011e-02 -5.76216839e-02  4.73474115e-02\n",
      " -1.39739485e-02 -8.30614418e-02 -7.04876613e-03  1.21097453e-02\n",
      "  3.21854390e-02  4.89696627e-03  5.87572865e-02  6.43140823e-02\n",
      " -7.24142464e-03 -1.07500507e-02  2.28356142e-02 -6.63218498e-02\n",
      " -5.34373708e-02 -8.19565058e-02 -1.06222644e-01  3.54442149e-02\n",
      " -1.88838765e-02  4.11298200e-02  2.44440157e-02 -6.06148206e-02\n",
      " -2.70905811e-02 -6.43142760e-02  1.25122792e-03  3.77689712e-02\n",
      "  1.99963767e-02 -2.55657379e-02  7.29813203e-02 -1.66820257e-03\n",
      "  3.64292786e-02 -1.86550617e-02 -2.03293338e-02 -2.82738614e-03\n",
      "  1.00480601e-01 -3.97173734e-03  3.70677700e-03 -2.51043495e-02\n",
      "  1.29317315e-02 -1.38116237e-02 -3.45576368e-03  7.64984414e-02]\n",
      "Embedding for Sentence 2: [ 7.80932419e-03 -1.05783595e-02 -4.89282832e-02 -5.22124134e-02\n",
      " -3.05008497e-02 -3.64469029e-02  1.64729692e-02 -1.08503047e-02\n",
      " -4.81360918e-03  5.78003116e-02  1.13672139e-02  3.22223864e-02\n",
      "  7.29330778e-02  8.33448246e-02 -5.50300523e-04  2.68764403e-02\n",
      " -1.83784626e-02 -1.72448307e-02  1.78121477e-02 -2.13410333e-02\n",
      " -7.82924332e-03 -3.57646644e-02 -7.71129727e-02  3.44520435e-02\n",
      " -3.37521359e-02  8.45391601e-02  3.88850123e-02  4.21468653e-02\n",
      " -1.30532710e-02 -3.66700925e-02 -5.99605739e-02 -5.74501641e-02\n",
      " -7.22043589e-02 -5.35660749e-03 -9.21346843e-02  4.32541184e-02\n",
      "  3.04286405e-02 -4.32421034e-03 -4.68982682e-02  5.43868355e-02\n",
      "  4.51772101e-03 -3.39122862e-02 -1.41513990e-02 -3.52579914e-02\n",
      "  1.80088840e-02  5.67470938e-02 -6.15063757e-02 -3.00865769e-02\n",
      "  2.85743512e-02 -4.39249910e-02  2.58018486e-02  3.90701853e-02\n",
      " -2.49067638e-02  8.88478197e-03 -6.47837371e-02 -4.39328849e-02\n",
      " -1.13456426e-02 -3.48718837e-02 -2.37735221e-03  8.05055872e-02\n",
      " -3.30597386e-02  3.02413129e-03 -2.94672176e-02 -3.01309954e-02\n",
      " -3.29682082e-02  8.07690900e-03  5.91505840e-02 -2.48848666e-02\n",
      " -5.86468726e-03  4.14430797e-02 -1.13019189e-02  1.12793306e-02\n",
      "  2.53947880e-02  1.24192275e-02 -1.85679048e-02 -3.27110626e-02\n",
      " -7.35548288e-02 -4.97005917e-02 -4.14870828e-02 -6.26457855e-02\n",
      "  2.60158777e-02  1.93748642e-02 -3.42676900e-02  6.24183891e-03\n",
      "  2.03998107e-02  6.12652227e-02 -5.08796563e-03 -1.92901175e-02\n",
      " -2.66750623e-02 -6.78753555e-02  7.50591829e-02 -2.59420909e-02\n",
      " -2.09534951e-02  2.24694610e-02  2.57565305e-02  1.75381117e-02\n",
      " -1.03438027e-01  4.57338318e-02 -6.92871539e-03 -1.03402629e-01\n",
      " -2.32698973e-02  2.57885829e-02  2.60337610e-02 -3.17960232e-02\n",
      " -4.58009765e-02 -4.22879048e-02 -1.35226799e-02 -3.41092311e-02\n",
      " -3.75748202e-02 -3.85746695e-02 -2.38050567e-03  6.83341250e-02\n",
      " -5.50799444e-02  1.21800313e-02  3.67938839e-02 -6.14123903e-02\n",
      "  4.51372331e-03  5.37733501e-03  3.85085568e-02 -3.55807729e-02\n",
      " -4.82840948e-02  5.03436513e-02 -6.74008066e-03 -7.02689514e-02\n",
      "  2.91995760e-02  2.67097112e-02 -4.78442647e-02  6.93137199e-02\n",
      "  4.33879122e-02  3.58528420e-02 -1.16553083e-02  6.28510788e-02\n",
      " -1.30507778e-02 -3.67334522e-02 -5.05193360e-02 -4.61725472e-03\n",
      " -2.55060326e-02 -1.73691642e-02 -4.28978913e-02 -7.17925429e-02\n",
      "  4.52660359e-02 -6.38585761e-02  1.40525289e-02 -4.58644591e-02\n",
      " -5.24438284e-02 -3.86173315e-02  4.58106771e-02 -6.75000250e-02\n",
      "  5.59170358e-02  1.94050353e-02  6.76326752e-02 -7.82529563e-02\n",
      " -5.42951524e-02  1.99102964e-02  7.91713037e-03 -4.58505563e-02\n",
      "  2.47244127e-02 -8.02826136e-02  7.73798092e-04  4.45491187e-02\n",
      " -3.95882688e-03  7.35854581e-02  1.43649494e-02  3.16385715e-03\n",
      " -3.38198803e-02  7.08030909e-02  1.23821935e-02  6.95129037e-02\n",
      " -4.46095355e-02 -3.54258064e-03  2.38837376e-02  3.85889038e-02\n",
      " -1.12454100e-02  4.23685461e-02  2.72211041e-02  3.21187228e-02\n",
      "  9.23956465e-03  2.60560699e-02  2.16007438e-02  4.69026156e-02\n",
      "  7.74756446e-02  3.55903022e-02  6.51383474e-02 -5.10393530e-02\n",
      "  5.55042084e-03  4.62943688e-02  5.17938919e-02  6.58757165e-02\n",
      " -5.62789254e-02  4.75319736e-02  9.87647623e-02  1.75569803e-02\n",
      " -3.50077339e-02 -3.24214250e-02  2.24604886e-02 -1.05352583e-03\n",
      " -9.78023838e-03  9.41272154e-02  5.05408198e-02  1.76047701e-02\n",
      " -8.17203000e-02  3.86277772e-02 -5.26854284e-02 -1.18586207e-02\n",
      "  3.49603146e-02 -7.82328844e-02 -2.03302167e-02 -2.24909056e-02\n",
      " -2.69820318e-02 -9.90714133e-03 -8.19371641e-03  1.27138952e-02\n",
      "  3.61597277e-02 -1.84632428e-02  8.12877417e-02 -7.75615573e-02\n",
      "  4.74814065e-02  1.38793699e-02  2.54730955e-02 -1.68525781e-02\n",
      "  4.65002935e-03  7.42668752e-03  3.77467088e-02 -4.37538214e-02\n",
      " -4.91020195e-02 -2.48197448e-02  6.63621277e-02  1.61155090e-02\n",
      " -8.34569782e-02  1.96074434e-02  2.22340580e-02  7.79780000e-02\n",
      "  3.49408388e-02  3.87273990e-02 -1.87858811e-03  3.05520203e-02\n",
      "  5.71613275e-02 -3.20964083e-02  6.02090843e-02 -3.39596160e-02\n",
      "  1.87093467e-02 -5.88715635e-03 -1.96571555e-02 -3.61998193e-02\n",
      " -3.33398618e-02  4.52223867e-02  7.24714599e-04 -3.35283130e-02\n",
      "  9.21707377e-02  7.75342137e-02 -7.87119381e-03  3.96146625e-02\n",
      " -6.73513860e-02  8.07019398e-02  5.57470433e-02 -1.00652345e-01\n",
      " -9.77375731e-02 -8.36594775e-02  4.74723540e-02  7.32318440e-04\n",
      "  6.42602816e-02 -2.26278584e-02 -5.72820380e-02  1.73609871e-02\n",
      "  3.17717493e-02  1.73114631e-02  6.10283986e-02 -8.90402421e-02\n",
      " -8.63310136e-03 -7.58332238e-02 -6.57030474e-03  3.17005143e-02\n",
      "  2.25119200e-02  1.92460865e-02 -2.77991947e-02  1.69330966e-02\n",
      "  7.84982443e-02 -4.35764864e-02  6.37219623e-02 -5.27971461e-02\n",
      " -5.41380830e-02 -2.09140852e-02 -3.68278287e-02  2.24378761e-02\n",
      " -1.51776103e-02 -6.88120648e-02 -1.66033313e-03  9.81045291e-02\n",
      "  1.56434122e-02 -3.25849578e-02  3.53568122e-02 -1.45329842e-02\n",
      " -2.90895216e-02  1.76705085e-02  4.13111076e-02 -8.21200162e-02\n",
      "  2.44224095e-03  8.26146733e-03  1.18621178e-02  1.75348539e-02\n",
      "  1.60132460e-02  1.45775359e-02  3.65804583e-02 -3.67728882e-02\n",
      " -2.84259822e-02  2.07250044e-02  1.58256013e-02 -2.97054239e-02\n",
      " -2.89502032e-02 -4.40336242e-02  1.36045944e-02  5.32434173e-02\n",
      "  6.85585365e-02 -3.30207869e-02  1.43265503e-03 -2.71144379e-02\n",
      "  9.52622294e-02 -4.25148234e-02 -1.51897846e-02  2.15725526e-02\n",
      "  8.92156269e-03 -1.87312905e-02  4.15017307e-02  4.48385812e-02\n",
      "  2.19686534e-02 -1.80601981e-02  6.91456944e-02  5.81430830e-02\n",
      "  2.41360962e-02 -7.08592460e-02  9.11063282e-04  1.71135267e-04\n",
      " -5.87306265e-03 -8.56671780e-02  5.51075898e-02  8.16025492e-03\n",
      " -5.97850271e-02 -2.49444880e-02  2.66845413e-02  3.30220386e-02\n",
      " -1.05413338e-02  3.61527763e-02 -1.49132898e-02  2.32245326e-02\n",
      " -1.03100181e-01 -6.71072826e-02 -4.54684123e-02  5.74570261e-02\n",
      " -8.16718787e-02  3.54727767e-02 -5.48466481e-02 -5.47089847e-03\n",
      " -8.97902809e-03 -8.53702649e-02  2.42095604e-03 -6.36476576e-02\n",
      " -9.80592594e-02 -1.00720273e-02  3.22668627e-02 -2.63039917e-02\n",
      " -7.83109888e-02 -1.36944447e-02 -9.86927077e-02 -2.20933612e-02\n",
      " -2.37234924e-02 -7.00060651e-02 -7.56410742e-03 -3.88610102e-02\n",
      "  4.07265276e-02 -6.45703152e-02  4.34872508e-03 -3.09594646e-02\n",
      "  5.60313724e-02  3.58020375e-03  5.97770885e-03  4.27107997e-02\n",
      " -6.58468306e-02 -3.85177806e-02  4.64543626e-02  2.75446158e-02\n",
      "  2.44292486e-02 -6.20559342e-02 -5.24427034e-02 -1.09820219e-03\n",
      " -6.37277588e-02  1.37647772e-02 -7.01982062e-03 -5.07895239e-02\n",
      " -5.30040190e-02 -4.93756570e-02 -2.96346433e-02  3.31186056e-02\n",
      " -3.91623266e-02  1.27952034e-02  6.80791261e-03  2.51287874e-02\n",
      "  9.45836771e-03 -9.84290540e-02 -5.77067472e-02 -7.44581744e-02\n",
      " -4.13135178e-02  2.46410146e-02  3.25051881e-02 -6.09793887e-02\n",
      "  2.89517525e-03  6.24366617e-03 -8.19963887e-02 -5.50386542e-03\n",
      " -1.24008860e-02  4.54878472e-02  4.07335460e-02 -3.19111645e-02\n",
      "  2.97839101e-02 -5.16546480e-02 -2.23517679e-02 -1.69766601e-02\n",
      " -2.55440250e-02  1.75913256e-02 -2.56326292e-02 -3.54576558e-02\n",
      "  5.16260043e-02 -7.31025338e-02 -3.05343157e-04  3.91398445e-02\n",
      "  4.84851040e-02 -5.10405973e-02 -1.36191444e-02 -1.31867547e-02\n",
      " -1.55870840e-02  6.50028437e-02 -2.70381533e-02 -2.90034134e-02\n",
      " -1.73953513e-03 -6.27312111e-04 -4.40771542e-02 -5.24109155e-02\n",
      " -6.86358986e-03  7.02806935e-02 -3.04966252e-02 -3.57946344e-02\n",
      " -1.67548824e-02 -4.84680943e-02 -2.57562678e-02 -2.33067013e-02\n",
      "  2.17219107e-02 -3.19745205e-02  2.93597877e-02  1.60771403e-02\n",
      "  6.55077696e-02  7.13539422e-02 -3.12701100e-03  6.96066990e-02\n",
      "  7.32196718e-02 -2.40972061e-02 -5.33727252e-05  1.08621875e-03\n",
      " -2.02395041e-02  7.80227631e-02 -8.06743186e-03  3.53083597e-03\n",
      "  5.96834272e-02  5.68736196e-02 -3.86070982e-02  7.55418018e-02\n",
      " -5.39402887e-02 -8.13449547e-02 -7.42923096e-02  2.38739289e-02\n",
      " -5.28979022e-03  2.71638390e-02 -1.88006703e-02  1.49167869e-02\n",
      "  3.19979228e-02 -6.25124574e-02 -7.52930939e-02 -5.35616428e-02\n",
      " -9.62475967e-03 -3.00362483e-02 -2.90043615e-02  4.58188690e-02\n",
      "  2.03850158e-02 -1.63280347e-03  6.85966536e-02 -5.24088275e-03\n",
      " -6.65411726e-02  2.90965531e-02 -6.33445680e-02  2.58218916e-03\n",
      "  2.51479596e-02  3.60899791e-02  2.77806148e-02 -2.66712718e-03\n",
      " -3.97094674e-02  2.62795277e-02  2.19663896e-04  1.39278104e-03\n",
      " -1.83054857e-04  1.70691069e-02 -1.03354715e-02  5.14791124e-02\n",
      "  3.83044556e-02 -3.70836891e-02 -9.12779346e-02  1.61108486e-02\n",
      "  8.08968320e-02 -8.51335004e-02  7.44031742e-02  1.19540952e-02\n",
      "  1.88196159e-03  8.57926160e-02 -1.37064802e-02  2.63199266e-02]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Download the USE model\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence.\", \"Another sentence for testing USE embeddings.\"]\n",
    "\n",
    "# Get USE embeddings\n",
    "embeddings = use_model(sentences)\n",
    "\n",
    "# Display embeddings\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Embedding for Sentence {i + 1}:\", embeddings[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2941090-6fe5-4804-a3e6-76bb93cde650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81ef053c-9f26-4d8e-ae5f-5112eb142dcf",
   "metadata": {},
   "source": [
    "# BART (Facebook's denoising autoencoder) - Hugging Face Transformers:\n",
    "## BART is a pre-trained sequence-to-sequence model that can be used for text generation and representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a63af3-4195-43b6-b31b-c45a94f1f877",
   "metadata": {},
   "source": [
    "## Methodology: Transformer-based model trained for text generation and summarization.\n",
    "## When to Use: Text generation, summarization.\n",
    "## Advantage: Effective for sequence-to-sequence tasks.\n",
    "## Disadvantage: Resource-intensive during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d8db8a7-376f-48cf-9bbf-9f146cca3e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['classification_head.dense.weight', 'classification_head.out_proj.weight', 'classification_head.dense.bias', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART Embedding: [[0.33659527 0.33027166 0.33313304]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForSequenceClassification.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"BART embeddings example.\"\n",
    "\n",
    "# Tokenize and get BART embeddings\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
    "logits = model(input_ids).logits\n",
    "output = torch.nn.functional.softmax(logits, dim=1).detach().numpy()\n",
    "\n",
    "# Display BART embeddings\n",
    "print(\"BART Embedding:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1e8a8-b625-4e5f-b162-fee0e54a1c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "545c8ec3-9fe3-4566-a69a-9b848f577d6e",
   "metadata": {},
   "source": [
    "# ELMo (Embeddings from Language Models) - TensorFlow Hub:\n",
    "## ELMo provides contextual word embeddings based on the internal states of a pre-trained language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d54e95-a280-4b2d-a377-f80a09d4af87",
   "metadata": {},
   "source": [
    "## Methodology: Contextual word embeddings using a bidirectional LSTM language model.\n",
    "## When to Use: Tasks requiring contextual embeddings.\n",
    "## Advantage: Captures word sense and context.\n",
    "## Disadvantage: Computationally expensive, less interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affc8bf-507e-4b87-a359-188e0c5e4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Download the ELMo model\n",
    "elmo_model = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence.\", \"Another sentence for testing ELMo embeddings.\"]\n",
    "\n",
    "# Get ELMo embeddings\n",
    "embeddings = elmo_model(sentences)[\"elmo\"]\n",
    "\n",
    "# Display embeddings\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"Embedding for Sentence {i + 1}:\", embeddings[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab93f2-e7d1-49b8-a9d5-4767246c2604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d58a4e5c-e01d-43f4-b674-0182f5afb426",
   "metadata": {},
   "source": [
    "# InferSent - Sent2Vec:\n",
    "## InferSent is a sentence embeddings method that is trained on natural language inference data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f258300-3738-446e-8440-2f2fac1d9203",
   "metadata": {},
   "source": [
    "## Methodology: Trained on natural language inference data using a sentence encoder.\n",
    "## When to Use: Sentence-level tasks, similarity analysis.\n",
    "## Advantage: Effective for sentence-level tasks.\n",
    "## Disadvantage: Limited to sentence embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4ce5a-a583-4045-a77f-827258829c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "import torch\n",
    "\n",
    "# Load InferSent model\n",
    "infersent_model = InferSent({'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048, 'pool_type': 'max'})\n",
    "infersent_model.load_state_dict(torch.load('path/to/infersent_model.pkl'))\n",
    "infersent_model.set_w2v_path('path/to/glove.840B.300d.txt')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence.\", \"Another sentence for testing InferSent embeddings.\"]\n",
    "\n",
    "# Build vocabulary\n",
    "infersent_model.build_vocab(sentences, tokenize=True)\n",
    "\n",
    "# Get InferSent embeddings\n",
    "embeddings = infersent_model.encode(sentences, tokenize=True)\n",
    "\n",
    "# Display embeddings\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"InferSent Embedding for Sentence {i + 1}:\", embeddings[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b90102-5954-4074-b333-4a236cb0dd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbde6f-b5fa-461a-8588-6beb3136a973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa38553-0b29-4984-a0d2-ffd68d1c5e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b75038-ce72-494d-809e-651a68be295a",
   "metadata": {},
   "source": [
    "# Text Embedding Categories: Semantic vs. Contextual\n",
    "\n",
    "## Semantic Embeddings:\n",
    "## 1. Focus on capturing word or sentence meanings.\n",
    "## 2. Suitable for tasks emphasizing meaning, where context may not be crucial.\n",
    "\n",
    "## Contextual Embeddings:\n",
    "## 1. Consider context for more nuanced and dynamic representations.\n",
    "## 2. Essential for tasks where understanding context is vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869aa52-1837-4bba-bbad-c67e66cff55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53bdfb62-a687-4314-af0f-4ab4cb56c301",
   "metadata": {},
   "source": [
    "### Semantic Text Embeddings:\n",
    "\n",
    "### Objective:\n",
    "### Capture the inherent meaning or semantics of words and sentences.\n",
    "### Aim to represent words with similar meanings as close vectors in the embedding space.\n",
    "\n",
    "### Examples: Word2Vec, GloVe, FastText: Learn embeddings based on co-occurrence patterns to encode semantic relationships.\n",
    "### InferSent: Trained on natural language inference data, capturing semantic relationships between sentences.\n",
    "\n",
    "### Characteristics:\n",
    "### Suitable for tasks where understanding the meaning of words or sentences is crucial.\n",
    "### Words with similar meanings should have similar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b8d74-a666-44fe-b633-4093fb6c464f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1fbc8a-2584-46e3-a87d-b363c19a5e60",
   "metadata": {},
   "source": [
    "### Contextual Text Embeddings:\n",
    "\n",
    "### Objective:\n",
    "### Consider the context in which words or sentences appear.\n",
    "### Embeddings vary based on the surrounding context, providing a more nuanced representation.\n",
    "\n",
    "### Examples:\n",
    "### ELMo (Embeddings from Language Models): Generates contextual embeddings by considering internal states of a language model.\n",
    "### BERT (Bidirectional Encoder Representations from Transformers): Produces contextualized word embeddings by considering bidirectional context.\n",
    "### GPT (Generative Pre-trained Transformer): Generates embeddings based on the entire context of a sentence.\n",
    "\n",
    "### Characteristics:\n",
    "### Valuable for tasks where the meaning of a word or sentence depends on the context.\n",
    "### Provides a more dynamic and adaptable representation, capturing nuances in meaning.\n",
    "\n",
    "### Overview:\n",
    "### Contextual embeddings consider the context in which words or sentences appear, allowing for more nuanced and adaptable representations.\n",
    "\n",
    "### Choosing Between Them:\n",
    "### Contextual Embeddings are essential for tasks where understanding context is vital, such as in natural language understanding and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcbfd4-7b5c-46eb-8b41-7f549894ab67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a304b42a-ebe0-4e17-abf9-460e98a4ab52",
   "metadata": {},
   "source": [
    "### Hybrid Approaches:\n",
    "\n",
    "### Some models combine both semantic and contextual aspects for richer representations.\n",
    "### Universal Sentence Encoder (USE): Embeds sentences with consideration of both semantic meaning and context.\n",
    "### SBERT (Sentence-BERT): Fine-tunes BERT specifically for sentence embeddings, capturing both semantic and contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91780cc3-437a-4035-a04f-a5dc93a5bd35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
